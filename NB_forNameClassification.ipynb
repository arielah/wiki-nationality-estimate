{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "random.seed(111)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CSV and filter / parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget https://github.com/arielah/CIS519_FinalProj/raw/master/annotated_names.tsv\n",
    "#looks like file is changing. work on local file for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filter_csv(csv, fn_idx = 0, ln_idx = 2, label_idx = 3, \n",
    "                     uniqID_idx = 4, delim = ',', max_name_len = 100,\n",
    "                    ngram=2, split_data = False, frac_train = 0.6,\n",
    "                    frac_val = 0.2, frac_test = 0.2):\n",
    "    \n",
    "    '''\n",
    "    INPUT: CSV or TSV with firstName, lastName, and label\n",
    "    in different columns and \n",
    "    \n",
    "    RETURNS: ordered lists of names, n-grams, and country labels.\n",
    "    \n",
    "        If split_data == True:\n",
    "            returns one of each of the above for train, test, and validation\n",
    "            with indicated splits\n",
    "    \n",
    "    Depending on the file, tell this function where to find:\n",
    "        fn_idx: column index of first name\n",
    "        ln_idx: column index of last name\n",
    "        labe_idx: column index of country label \n",
    "        delmim: what to split lines by to get columns\n",
    "    \n",
    "    Filters:\n",
    "        lines with characters from bad_chars (see below)\n",
    "        names longer than 100 characters\n",
    "        names with label \"Other\"\n",
    "        names with firstName and/or lastName with less than 2 characters\n",
    "        names that are exact duplicates within a country label \n",
    "    \n",
    "    NOTE: Name lists returned are ordered by accessing dictionary\n",
    "    keys corresponding to countries. You probably want to shuffle these\n",
    "    before using them for testing, training, etc. \n",
    "    \n",
    "    TO-DO: keep track of uniqID indexes when/if that is added\n",
    "    '''\n",
    "    random.seed(111)\n",
    "    count_dic = {} \n",
    "    bad_chars = ['!', '\"', '%', '&', '(', ')', '*', '/',':', ';', \n",
    "                 '=', '?', '@',']', '_', '`','{', '|', '}', '~'] \n",
    "    for x in range(0,10):\n",
    "        bad_chars.append(str(x))\n",
    "    all_lines = 0\n",
    "    final_lines = 0\n",
    "    line_lens = []\n",
    "    name_dic = {}\n",
    "    bad_char_lines = 0\n",
    "    all_letters = set([])\n",
    "    fd = open(csv,'r')\n",
    "    print('Header:\\n%s'%fd.readline())\n",
    "    for line in fd:\n",
    "        bad_char = False\n",
    "        all_lines += 1\n",
    "        l = line.strip().split(delim)\n",
    "        if not len(l) == 4:\n",
    "            print(l)\n",
    "            continue\n",
    "        fn = l[fn_idx].strip()\n",
    "        ln = l[ln_idx].strip()\n",
    "        country = l[label_idx].strip()\n",
    "        if country == 'Other':\n",
    "            continue\n",
    "        if len(fn) < 2:\n",
    "            continue\n",
    "        if len(ln) < 2:\n",
    "            continue\n",
    "        name_len = len(fn) + len(ln)\n",
    "        #check names for characters\n",
    "        full_name = fn + ' ' + ln\n",
    "        for char in full_name:\n",
    "            if char in bad_chars:\n",
    "                #print('##%s##'%char, line)\n",
    "                bad_char = True\n",
    "                bad_char_lines += 1\n",
    "            else:\n",
    "                all_letters.add(char)\n",
    "        if bad_char == True:\n",
    "            continue\n",
    "        if name_len > 100: \n",
    "            continue\n",
    "        final_lines += 1\n",
    "        try:\n",
    "            count_dic[country] += 1\n",
    "            name_dic[country].add(full_name)\n",
    "        except:\n",
    "            count_dic[country] = 1\n",
    "            name_dic[country] = set([full_name])\n",
    "    print('All lines processed:%s\\nLines meeting criteria:%s'%(all_lines, final_lines))\n",
    "    print('total bad char lines: %s'%bad_char_lines)\n",
    "    print('Here are for each country the # of valid names and # uniq valid names:')\n",
    "    name_list = []\n",
    "    label_list = []\n",
    "    doc_list = []\n",
    "    for c in count_dic.keys():\n",
    "        print('%s\\t%s\\t%s'%(c, count_dic[c], len(name_dic[c])))\n",
    "        for full_name in name_dic[c]:\n",
    "            nChars = [full_name[i:i+ngram] for i in range(len(full_name)-(ngram-1))]\n",
    "            doc_list.append(nChars)\n",
    "            name_list.append(full_name)\n",
    "            label_list.append(c)\n",
    "    fd.close()\n",
    "    print('FINAL NAME COUNT: %s'%len(name_list))\n",
    "    if split_data == True:\n",
    "        n_test = int(len(name_list) * frac_test)\n",
    "        n_val = int(len(name_list) * frac_val)\n",
    "        #first split test off\n",
    "        doc_train, doc_test, y_train, y_test, name_train, name_test = train_test_split(doc_list, label_list, name_list, stratify=label_list, test_size=n_test, random_state=1)\n",
    "        #next split gives 20% to validation\n",
    "        doc_train, doc_val, y_train, y_val, name_train, name_val = train_test_split(doc_train, y_train, name_train, stratify=y_train, test_size=n_val, random_state=1)\n",
    "        print('split to train,val, test data with these lengths:')\n",
    "        print('train: %s, validation: %s, test: %s'%(len(doc_train), len(doc_val), len(doc_test)))\n",
    "        return doc_train, doc_test, doc_val, y_train, y_test, y_val, name_train, name_test, name_val\n",
    "    else:\n",
    "        return name_list, doc_list, label_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header:\n",
      "name_first\tname_middle\tname_last\tethnicity\n",
      "\n",
      "All lines processed:708494\n",
      "Lines meeting criteria:698455\n",
      "total bad char lines: 4027\n",
      "Here are for each country the # of valid names and # uniq valid names:\n",
      "Europe\t294321\t279447\n",
      "Muslim\t29833\t28956\n",
      "North America\t171393\t158848\n",
      "Asia\t78539\t75341\n",
      "Hispanic\t53816\t47938\n",
      "Pacific\t37751\t35935\n",
      "Africa\t28357\t27967\n",
      "Israeli\t4445\t4410\n",
      "FINAL NAME COUNT: 658842\n"
     ]
    }
   ],
   "source": [
    "name_list, doc_list, label_list = parse_filter_csv('./CIS519_FinalProj/annotated_names.tsv',delim='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header:\n",
      "name_first\tname_middle\tname_last\tethnicity\n",
      "\n",
      "All lines processed:708494\n",
      "Lines meeting criteria:698455\n",
      "total bad char lines: 4027\n",
      "Here are for each country the # of valid names and # uniq valid names:\n",
      "Europe\t294321\t279447\n",
      "Muslim\t29833\t28956\n",
      "North America\t171393\t158848\n",
      "Asia\t78539\t75341\n",
      "Hispanic\t53816\t47938\n",
      "Pacific\t37751\t35935\n",
      "Africa\t28357\t27967\n",
      "Israeli\t4445\t4410\n",
      "FINAL NAME COUNT: 658842\n",
      "split to train,val, test data with these lengths:\n",
      "train: 395306, validation: 131768, test: 131768\n"
     ]
    }
   ],
   "source": [
    "D_train, D_test, D_valid, y_train, y_test, y_valid, name_train, name_test, name_valid = parse_filter_csv('./CIS519_FinalProj/annotated_names.tsv',delim='\\t', split_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used for NB algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(D):\n",
    "    \"\"\"\n",
    "    Given a list of documents, where each document is represented as\n",
    "    a list of tokens, return the resulting vocabulary. The vocabulary\n",
    "    should be a set of tokens which appear more than once in the entire\n",
    "    document collection plus the \"<unk>\" token.\n",
    "    \"\"\"\n",
    "    vocab = set([])\n",
    "    count_dic = {}\n",
    "    for doc in D:\n",
    "        for token in doc:\n",
    "            try:\n",
    "                count_dic[token] += 1\n",
    "                vocab.add(token)\n",
    "            except:\n",
    "                count_dic[token] = 0\n",
    "    vocab.add('<unk>')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoWFeaturizer(object):\n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and the vocabulary\n",
    "        as a set of tokens, compute the binary bag-of-words feature representation.\n",
    "        This function should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        feats = {}\n",
    "        for token in doc:\n",
    "            if token in vocab:\n",
    "                feats[token] = 1\n",
    "            else:\n",
    "                feats[\"<unk>\"] = 1\n",
    "        return feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBoWFeaturizer(object):\n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and the vocabulary\n",
    "        as a set of tokens, compute the count bag-of-words feature representation.\n",
    "        This function should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        feats = {}\n",
    "        for token in doc:\n",
    "            if token in vocab:\n",
    "                try:\n",
    "                    feats[token] += 1\n",
    "                except:\n",
    "                    feats[token] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    feats[\"<unk>\"] += 1\n",
    "                except:\n",
    "                    feats[\"<unk>\"] = 1                    \n",
    "        return feats    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(D, vocab):\n",
    "    \"\"\"\n",
    "    Given a list of documents D and the vocabulary as a set of tokens,\n",
    "    where each document is represented as a list of tokens, return the IDF scores\n",
    "    for every token in the vocab. The IDFs should be represented as a dictionary that\n",
    "    maps from the token to the IDF value. If a token is not present in the\n",
    "    vocab, it should be mapped to \"<unk>\".\n",
    "    \"\"\"\n",
    "    doc_counts = {}\n",
    "    for doc in D:\n",
    "        feats = BBoWFeaturizer().convert_document_to_feature_dictionary(doc, vocab)\n",
    "        for f in feats:\n",
    "            try:\n",
    "                doc_counts[f] += 1\n",
    "            except:\n",
    "                doc_counts[f] = 1\n",
    "    idf_dic = {}\n",
    "    len_D = float(len(D))\n",
    "    for token in vocab:\n",
    "        idf = np.log((len_D / doc_counts[token]))\n",
    "        idf_dic[token] = idf\n",
    "    return idf_dic\n",
    "    \n",
    "class TFIDFFeaturizer(object):\n",
    "    def __init__(self, idf):\n",
    "        \"\"\"The idf scores computed via `compute_idf`.\"\"\"\n",
    "        self.idf = idf\n",
    "    \n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and\n",
    "        the vocabulary as a set of tokens, compute\n",
    "        the TF-IDF feature representation. This function\n",
    "        should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        feats = {}\n",
    "        counts = CBoWFeaturizer().convert_document_to_feature_dictionary(doc, vocab)\n",
    "        for token in counts.keys():\n",
    "            feats[token] = counts[token] * self.idf[token]\n",
    "        return feats      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not need to edit this cell\n",
    "def load_dataset(file_path):\n",
    "    D = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            instance = json.loads(line)\n",
    "            D.append(instance['document'])\n",
    "            y.append(instance['label'])\n",
    "    return D, y\n",
    "\n",
    "def convert_to_features(D, featurizer, vocab):\n",
    "    X = []\n",
    "    for doc in D:\n",
    "        X.append(featurizer.convert_document_to_feature_dictionary(doc, vocab))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X, y, k, vocab):\n",
    "    \"\"\"\n",
    "    Computes the statistics for the Naive Bayes classifier.\n",
    "    X is a list of feature representations, where each representation\n",
    "    is a dictionary that maps from the feature name to the value.\n",
    "    y is a list of integers that represent the labels.\n",
    "    k is a float which is the smoothing parameters.\n",
    "    vocab is the set of vocabulary tokens.\n",
    "    \n",
    "    Returns two values:\n",
    "        p_y: A dictionary from the label to the corresponding p(y) score\n",
    "        p_v_y: A nested dictionary where the outer dictionary's key is\n",
    "            the label and the innner dictionary maps from a feature\n",
    "            to the probability p(v|y). For example, `p_v_y[1][\"hello\"]`\n",
    "            should be p(v=\"hello\"|y=1).\n",
    "    \"\"\"\n",
    "    p_y = {}\n",
    "    p_v_y = {}\n",
    "    y = np.array(y)\n",
    "    labels = set(y)\n",
    "    total = float(len(y))\n",
    "    for label in labels:\n",
    "        label_idx = np.where(y == label)[0]\n",
    "        p_y[label] = len(label_idx) / total    \n",
    "        label_token_sum_dic = {}\n",
    "        label_vocab_total = 0                       \n",
    "        for idx in label_idx:\n",
    "            doc = X[idx]\n",
    "            for token in doc.keys():\n",
    "                label_vocab_total += doc[token]\n",
    "                try:\n",
    "                    label_token_sum_dic[token] += doc[token]\n",
    "                except:\n",
    "                    label_token_sum_dic[token] = doc[token]\n",
    "        p_v_y[label] = {}\n",
    "        vocab_len = len(vocab)\n",
    "        for token in vocab:\n",
    "            try:\n",
    "                p_v_y[label][token] = (k + label_token_sum_dic[token]) / float(k * vocab_len + label_vocab_total)\n",
    "            except:\n",
    "                p_v_y[label][token] = k / float(k * vocab_len + label_vocab_total)\n",
    "    return p_y, p_v_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(D, p_y, p_v_y):\n",
    "    \"\"\"\n",
    "    Runs the prediction rule for Naive Bayes. D is a list of documents,\n",
    "    where each document is a list of tokens.\n",
    "    p_y and p_v_y are output from `train_naive_bayes`.\n",
    "    \n",
    "    Note that any token which is not in p_v_y should be mapped to\n",
    "    \"<unk>\". Further, the input dictionaries are probabilities. You\n",
    "    should convert them to log-probabilities while you compute\n",
    "    the Naive Bayes prediction rule to prevent underflow errors.\n",
    "    \n",
    "    Returns two values:\n",
    "        predictions: A list of integer labels, one for each document,\n",
    "            that is the predicted label for each instance.\n",
    "        confidences: A list of floats, one for each document, that is\n",
    "            p(y|d) for the corresponding label that is returned.\n",
    "    \"\"\"\n",
    "    labels = list(p_y.keys())\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for doc in D:\n",
    "        label_LLs = []\n",
    "        for label in labels:\n",
    "            label_prob = np.log(p_y[label])\n",
    "            for token in doc:\n",
    "                try:\n",
    "                    label_prob += np.log(p_v_y[label][token])\n",
    "                except:\n",
    "                    label_prob += np.log(p_v_y[label]['<unk>'])\n",
    "            label_LLs.append(label_prob)\n",
    "        label_LLs = np.array(label_LLs)\n",
    "        log_prob_data = np.logaddexp.reduce(label_LLs)\n",
    "        pred_idx = np.argmax(label_LLs)\n",
    "        predictions.append(labels[pred_idx])\n",
    "        log_conf = label_LLs[pred_idx] - log_prob_data\n",
    "        confidences.append(np.exp(log_conf))\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, k, vocab, mode):\n",
    "    \"\"\"\n",
    "    Trains the Naive Bayes classifier using the semi-supervised algorithm.\n",
    "    \n",
    "    X_sup (Sx): A list of the featurized supervised documents.\n",
    "    y_sup (Sy): A list of the corresponding supervised labels.\n",
    "    D_unsup (Ud): The unsupervised documents.\n",
    "    X_unsup (Ux): The unsupervised document representations.\n",
    "    D_valid: The validation documents.\n",
    "    y_valid: The validation labels.\n",
    "    k: The smoothing parameter for Naive Bayes.\n",
    "    vocab: The vocabulary as a set of tokens.\n",
    "    mode: either \"threshold\" or \"top-k\", depending on which selection\n",
    "        algorithm should be used.\n",
    "    \n",
    "    Returns the final p_y and p_v_y (see `train_naive_bayes`) after the\n",
    "    algorithm terminates.    \n",
    "    \"\"\"\n",
    "    stop = False\n",
    "    counter = 0\n",
    "    p_y_list = []\n",
    "    p_v_y_list = []\n",
    "    \n",
    "    while stop == False:\n",
    "        p_y, p_v_y = train_naive_bayes(X_sup, y_sup, k, vocab)\n",
    "        p_y_list.append(p_y)\n",
    "        p_v_y_list.append(p_v_y)        \n",
    "        if counter == 0:\n",
    "            val_preds_0, val_confs_0 = predict_naive_bayes(D_valid, p_y, p_v_y)\n",
    "            val_acc_0 = accuracy_score(y_valid, val_preds_0)\n",
    "            print('starting validation accuracy: %s'%val_acc_0)\n",
    "            trash = []\n",
    "        counter += 1\n",
    "        #U_y, P_y  returned\n",
    "        preds, confs = predict_naive_bayes(D_unsup, p_y_list[-1], p_v_y_list[-1])\n",
    "        #stuff to add to the supervised set\n",
    "        if mode == \"threshold\":\n",
    "            print('running threshold mode at confidence above 0.98...')\n",
    "            conf_thresh = 0.98\n",
    "            add_to_sup_idxes = np.where(np.array(confs) > conf_thresh)[0]\n",
    "        elif mode == \"top-k\":\n",
    "            print('running top-K mode with K=10,000...')\n",
    "            K = 10000\n",
    "            #reverse sort indexes, top K \n",
    "            add_to_sup_idxes = np.argsort(np.array(confs))[::-1][:K] \n",
    "        else:\n",
    "            raise(RuntimeError('unrecognized mode (%s). Use \"threshold\" or \"top-k\"'%mode))        \n",
    "        \n",
    "        if len(add_to_sup_idxes) == 0:\n",
    "            stop = True\n",
    "        else:\n",
    "            #Add_to, Remove_from\n",
    "            print('for step %s will add %s to supervised list'%(counter, len(add_to_sup_idxes)))\n",
    "            print('\\t\\tStarting Sup length %s; Unsup length %s'%(len(X_sup), len(X_unsup)))   \n",
    "            X_sup, X_unsup = add_and_remove_indexes(X_sup, X_unsup, add_to_sup_idxes)\n",
    "            y_sup, preds = add_and_remove_indexes(y_sup, preds, add_to_sup_idxes)\n",
    "            trash, D_unsup = add_and_remove_indexes(trash, D_unsup, add_to_sup_idxes)\n",
    "            print('\\t\\tResulting Sup length %s; Unsup length %s'%(len(X_sup), len(X_unsup)))   \n",
    "    print('\\twent through %s iterations before stopping'%counter)\n",
    "    val_preds, val_confs = predict_naive_bayes(D_valid, p_y_list[-1], p_v_y_list[-1])\n",
    "    val_acc_fin = accuracy_score(y_valid, val_preds)\n",
    "    print('final validation accuracy: %s'%val_acc_fin)\n",
    "    return p_y_list[-1], p_v_y_list[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_remove_indexes(list_to_add_to, list_to_delete_from, indexes_from_delete_list):\n",
    "    \n",
    "    '''\n",
    "    Takes two lists and a a list of valid indexes that correspond to\n",
    "    the items that should be moved from the second list to the first.\n",
    "    Items are deleted from the second and appended to the end of the first. \n",
    "    Returns both lists \n",
    "    '''\n",
    "    a = list_to_add_to\n",
    "    b = list_to_delete_from\n",
    "    for index in sorted(indexes_from_delete_list, reverse = True):\n",
    "        a.append(list_to_delete_from[index]) \n",
    "        #print('removing index %s'%index)\n",
    "        del b[index]\n",
    "        #print('adding list len: %s ; del list len: %s'%(len(list_to_add_to), len(list_to_delete_from)))\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_semi_supervised(k = 0.1, mode = 'top-k', starting_size = 50, data_path = './', featurizer = CBoWFeaturizer()):\n",
    "    \n",
    "    '''\n",
    "    Function that splits training data based on starting_size and\n",
    "    trains semi-supervised NB based on given k, mode, and featurizer method\n",
    "    '''\n",
    "    random.seed(111) \n",
    "    D_train, y_train = load_dataset(data_path + 'data/train.jsonl')\n",
    "    D_valid, y_valid = load_dataset(data_path + 'data/valid.jsonl')    \n",
    "    vocab = get_vocabulary(D_train)\n",
    "    X_train = convert_to_features(D_train, featurizer, vocab)\n",
    "    \n",
    "    rand_indexes = random.sample(range(0, len(y_train)), starting_size)\n",
    "    print('first 10 indexes for labeled data are: %s'%(rand_indexes[:10]))\n",
    "    D_sup = []\n",
    "    y_sup = []\n",
    "    X_sup = []\n",
    "    #Add_to, Remove_From\n",
    "    D_sup, D_train = add_and_remove_indexes(D_sup, D_train, rand_indexes)\n",
    "    X_sup, X_train = add_and_remove_indexes(X_sup, X_train, rand_indexes)\n",
    "    y_sup, y_train = add_and_remove_indexes(y_sup, y_train, rand_indexes)\n",
    "    print('sup data size: %s and unsup size: %s'%(len(D_sup), len(D_train)))\n",
    "    p_y_FINAL, p_v_y_FINAL = train_semi_supervised(X_sup, y_sup, D_train, X_train, D_valid, y_valid, k, vocab, mode)\n",
    "    D_test, y_test = load_dataset(data_path + 'data/test.jsonl')\n",
    "    test_pred, test_conf = predict_naive_bayes(D_test, p_y_FINAL, p_v_y_FINAL)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    print(\"FINAL TEST ACCURACY: %s\"%test_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: NB Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148\n"
     ]
    }
   ],
   "source": [
    "# Variables that are named D_* are lists of documents where each\n",
    "# document is a list of tokens. y_* is a list of integer class labels.\n",
    "# X_* is a list of the feature dictionaries for each document.\n",
    "# D_train, y_train = load_dataset('data/train.jsonl')\n",
    "# D_valid, y_valid = load_dataset('data/valid.jsonl')\n",
    "# D_test, y_test = load_dataset('data/test.jsonl')\n",
    "\n",
    "vocab = get_vocabulary(D_train)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features for the three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148\n",
      "extracting BBoW\n",
      "extracting CBoW\n",
      "extracting TFIDF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = get_vocabulary(D_train)\n",
    "print(len(vocab))\n",
    "\n",
    "print('extracting BBoW')\n",
    "featurizer = BBoWFeaturizer()\n",
    "X_train_BBoW = convert_to_features(D_train, featurizer, vocab)\n",
    "print('extracting CBoW')\n",
    "featurizer = CBoWFeaturizer()\n",
    "X_train_CBoW = convert_to_features(D_train, featurizer, vocab)\n",
    "print('extracting TFIDF')\n",
    "featurizer = TFIDFFeaturizer(compute_idf(D_train, vocab))\n",
    "X_train_TFIDF = convert_to_features(D_train, featurizer, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter sweep over k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training NB on BBoW with k=0.001...\n",
      "training NB on CBoW with k=0.001...\n",
      "training NB on TFIDF with k=0.001...\n",
      "training NB on BBoW with k=0.01...\n",
      "training NB on CBoW with k=0.01...\n",
      "training NB on TFIDF with k=0.01...\n",
      "training NB on BBoW with k=0.1...\n",
      "training NB on CBoW with k=0.1...\n",
      "training NB on TFIDF with k=0.1...\n",
      "training NB on BBoW with k=1.0...\n",
      "training NB on CBoW with k=1.0...\n",
      "training NB on TFIDF with k=1.0...\n",
      "training NB on BBoW with k=10.0...\n",
      "training NB on CBoW with k=10.0...\n",
      "training NB on TFIDF with k=10.0...\n"
     ]
    }
   ],
   "source": [
    "ks = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "BBoW_p_ys = []\n",
    "BBoW_p_v_ys = []\n",
    "CBoW_p_ys = []\n",
    "CBoW_p_v_ys = []\n",
    "TFIDF_p_ys = []\n",
    "TFIDF_p_v_ys = []\n",
    "for k in ks:\n",
    "    print('training NB on BBoW with k=%s...'%k)\n",
    "    BBoW_p_y, BBoW_p_v_y = train_naive_bayes(X_train_BBoW, y_train, k, vocab)\n",
    "    BBoW_p_ys.append(BBoW_p_y)\n",
    "    BBoW_p_v_ys.append(BBoW_p_v_y)\n",
    "    print('training NB on CBoW with k=%s...'%k)\n",
    "    CBoW_p_y, CBoW_p_v_y = train_naive_bayes(X_train_CBoW, y_train, k, vocab)\n",
    "    CBoW_p_ys.append(CBoW_p_y)\n",
    "    CBoW_p_v_ys.append(CBoW_p_v_y)\n",
    "    print('training NB on TFIDF with k=%s...'%k)\n",
    "    TFIDF_p_y, TFIDF_p_v_y = train_naive_bayes(X_train_TFIDF, y_train, k, vocab)\n",
    "    TFIDF_p_ys.append(TFIDF_p_y)\n",
    "    TFIDF_p_v_ys.append(TFIDF_p_v_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and validation accuracies for 3 feature methods for all ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictiong on k=0...\n",
      "\tpredicting BBoW...\n",
      "\t\ttrain acc: 0.5710032228197902\n",
      "\t\tval acc: 0.5663059316374234\n",
      "\tpredicting CBoW...\n",
      "\t\ttrain acc: 0.5709450400449272\n",
      "\t\ttrain acc: 0.5709450400449272\n",
      "\tpredicting TFIDF...\n",
      "\t\ttrain acc: 0.561256343187303\n",
      "\t\ttrain acc: 0.561256343187303\n",
      "predictiong on k=1...\n",
      "\tpredicting BBoW...\n",
      "\t\ttrain acc: 0.5709323916156092\n",
      "\t\tval acc: 0.5664197680772266\n",
      "\tpredicting CBoW...\n",
      "\t\ttrain acc: 0.5708868572700642\n",
      "\t\ttrain acc: 0.5708868572700642\n",
      "\tpredicting TFIDF...\n"
     ]
    }
   ],
   "source": [
    "BBoW_val_accs = []\n",
    "BBoW_train_accs = []\n",
    "\n",
    "CBoW_val_accs = []\n",
    "CBoW_train_accs = []\n",
    "\n",
    "TFIDF_val_accs = []\n",
    "TFIDF_train_accs = []\n",
    "\n",
    "for n in range(len(ks)):\n",
    "    print('predictiong on k=%s...'%ks[n])\n",
    "    print('\\tpredicting BBoW...')\n",
    "    pred, conf = predict_naive_bayes(D_train, BBoW_p_ys[n], BBoW_p_v_ys[n])\n",
    "    acc_train = accuracy_score(y_train, pred)\n",
    "    BBoW_train_accs.append(acc_train)\n",
    "    print('\\t\\ttrain acc: %s'%acc_train)\n",
    "    \n",
    "    pred, conf = predict_naive_bayes(D_valid, BBoW_p_ys[n], BBoW_p_v_ys[n])\n",
    "    acc_val = accuracy_score(y_valid, pred)\n",
    "    BBoW_val_accs.append(acc_val)\n",
    "    print('\\t\\tval acc: %s'%acc_val)\n",
    "    \n",
    "    print('\\tpredicting CBoW...')    \n",
    "    pred, conf = predict_naive_bayes(D_train, CBoW_p_ys[n], CBoW_p_v_ys[n])\n",
    "    acc_train = accuracy_score(y_train, pred)\n",
    "    CBoW_train_accs.append(acc_train)       \n",
    "    print('\\t\\ttrain acc: %s'%acc_train)\n",
    "    \n",
    "    pred, conf = predict_naive_bayes(D_valid, CBoW_p_ys[n], CBoW_p_v_ys[n])\n",
    "    acc_val = accuracy_score(y_valid, pred)\n",
    "    CBoW_val_accs.append(acc_val)      \n",
    "    print('\\t\\tval acc: %s'%acc_val)   \n",
    "    \n",
    "    print('\\tpredicting TFIDF...')\n",
    "    pred, conf = predict_naive_bayes(D_train, TFIDF_p_ys[n], TFIDF_p_v_ys[n])\n",
    "    acc_train = accuracy_score(y_train, pred)\n",
    "    TFIDF_train_accs.append(acc_train)     \n",
    "    print('\\t\\ttrain acc: %s'%acc_train)\n",
    "    \n",
    "    pred, conf = predict_naive_bayes(D_valid, TFIDF_p_ys[n], TFIDF_p_v_ys[n])\n",
    "    acc_val = accuracy_score(y_valid, pred)\n",
    "    TFIDF_val_accs.append(acc_val)        \n",
    "    print('\\t\\tval acc: %s'%acc_val)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BBoW_val_accs, max(BBoW_val_accs))\n",
    "print(CBoW_val_accs, max(CBoW_val_accs))\n",
    "print(TFIDF_val_accs, max(TFIDF_val_accs))\n",
    "\n",
    "fw = open('NB_accuracies.txt','w')\n",
    "fw.write('#Method\\t%s\\n'%('\\t'.join([str(x) for x in ks])))\n",
    "\n",
    "fw.write('BBoW_train_accs\\t%s\\n'%'\\t'.join([str(x) for x in BBoW_train_accs]))\n",
    "fw.write('CBoW_train_accs\\t%s\\n'%'\\t'.join([str(x) for x in CBoW_train_accs]))\n",
    "fw.write('TFIDF_train_accs\\t%s\\n'%'\\t'.join([str(x) for x in TFIDF_train_accs]))\n",
    "\n",
    "fw.write('BBoW_val_accs\\t%s\\n'%'\\t'.join([str(x) for x in BBoW_val_accs]))\n",
    "fw.write('CBoW_val_accs\\t%s\\n'%'\\t'.join([str(x) for x in CBoW_val_accs]))\n",
    "fw.write('TFIDF_val_accs\\t%s\\n'%'\\t'.join([str(x) for x in TFIDF_val_accs]))\n",
    "fw.close()                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print validation accuracy at best value of k for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 0.8608 0.83\n"
     ]
    }
   ],
   "source": [
    "pred, conf = predict_naive_bayes(D_test, BBoW_p_ys[2], BBoW_p_v_ys[2])\n",
    "test_acc_bbow = accuracy_score(y_test, pred)\n",
    "pred, conf = predict_naive_bayes(D_test, CBoW_p_ys[2], CBoW_p_v_ys[2])\n",
    "test_acc_cbow = accuracy_score(y_test, pred)\n",
    "pred, conf = predict_naive_bayes(D_test, TFIDF_p_ys[3], TFIDF_p_v_ys[3])\n",
    "test_acc_tfidf = accuracy_score(y_test, pred)\n",
    "print(test_acc_bbow, test_acc_cbow, test_acc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 2: Semi-supervised experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call run_semi_supervised(mode = threshold) which prints accuracies (and other stuff) for the three starting sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 50 and unsup size: 44950\n",
      "starting validation accuracy: 0.6564\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 1 will add 38949 to supervised list\n",
      "\t\tStarting Sup length 50; Unsup length 44950\n",
      "\t\tResulting Sup length 38999; Unsup length 6001\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 2 will add 4268 to supervised list\n",
      "\t\tStarting Sup length 38999; Unsup length 6001\n",
      "\t\tResulting Sup length 43267; Unsup length 1733\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 3 will add 281 to supervised list\n",
      "\t\tStarting Sup length 43267; Unsup length 1733\n",
      "\t\tResulting Sup length 43548; Unsup length 1452\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 4 will add 23 to supervised list\n",
      "\t\tStarting Sup length 43548; Unsup length 1452\n",
      "\t\tResulting Sup length 43571; Unsup length 1429\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 5 will add 3 to supervised list\n",
      "\t\tStarting Sup length 43571; Unsup length 1429\n",
      "\t\tResulting Sup length 43574; Unsup length 1426\n",
      "running threshold mode at confidence above 0.98...\n",
      "\twent through 6 iterations before stopping\n",
      "final validation accuracy: 0.7028\n",
      "FINAL TEST ACCURACY: 0.696\n",
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 500 and unsup size: 44500\n",
      "starting validation accuracy: 0.776\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 1 will add 37653 to supervised list\n",
      "\t\tStarting Sup length 500; Unsup length 44500\n",
      "\t\tResulting Sup length 38153; Unsup length 6847\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 2 will add 4929 to supervised list\n",
      "\t\tStarting Sup length 38153; Unsup length 6847\n",
      "\t\tResulting Sup length 43082; Unsup length 1918\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 3 will add 220 to supervised list\n",
      "\t\tStarting Sup length 43082; Unsup length 1918\n",
      "\t\tResulting Sup length 43302; Unsup length 1698\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 4 will add 21 to supervised list\n",
      "\t\tStarting Sup length 43302; Unsup length 1698\n",
      "\t\tResulting Sup length 43323; Unsup length 1677\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 5 will add 1 to supervised list\n",
      "\t\tStarting Sup length 43323; Unsup length 1677\n",
      "\t\tResulting Sup length 43324; Unsup length 1676\n",
      "running threshold mode at confidence above 0.98...\n",
      "\twent through 6 iterations before stopping\n",
      "final validation accuracy: 0.77\n",
      "FINAL TEST ACCURACY: 0.76\n",
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 5000 and unsup size: 40000\n",
      "starting validation accuracy: 0.826\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 1 will add 33871 to supervised list\n",
      "\t\tStarting Sup length 5000; Unsup length 40000\n",
      "\t\tResulting Sup length 38871; Unsup length 6129\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 2 will add 3862 to supervised list\n",
      "\t\tStarting Sup length 38871; Unsup length 6129\n",
      "\t\tResulting Sup length 42733; Unsup length 2267\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 3 will add 222 to supervised list\n",
      "\t\tStarting Sup length 42733; Unsup length 2267\n",
      "\t\tResulting Sup length 42955; Unsup length 2045\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 4 will add 16 to supervised list\n",
      "\t\tStarting Sup length 42955; Unsup length 2045\n",
      "\t\tResulting Sup length 42971; Unsup length 2029\n",
      "running threshold mode at confidence above 0.98...\n",
      "for step 5 will add 2 to supervised list\n",
      "\t\tStarting Sup length 42971; Unsup length 2029\n",
      "\t\tResulting Sup length 42973; Unsup length 2027\n",
      "running threshold mode at confidence above 0.98...\n",
      "\twent through 6 iterations before stopping\n",
      "final validation accuracy: 0.782\n",
      "FINAL TEST ACCURACY: 0.7792\n"
     ]
    }
   ],
   "source": [
    "start_sizes = [50, 500, 5000]\n",
    "\n",
    "for s in start_sizes:\n",
    "    run_semi_supervised(k = 0.1, starting_size = s, mode = 'threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call run_semi_supervised(mode = threshold) which prints accuracies (and other stuff) for the three starting sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 50 and unsup size: 44950\n",
      "starting validation accuracy: 0.6564\n",
      "running top-K mode with K=10,000...\n",
      "for step 1 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 50; Unsup length 44950\n",
      "\t\tResulting Sup length 10050; Unsup length 34950\n",
      "running top-K mode with K=10,000...\n",
      "for step 2 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 10050; Unsup length 34950\n",
      "\t\tResulting Sup length 20050; Unsup length 24950\n",
      "running top-K mode with K=10,000...\n",
      "for step 3 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 20050; Unsup length 24950\n",
      "\t\tResulting Sup length 30050; Unsup length 14950\n",
      "running top-K mode with K=10,000...\n",
      "for step 4 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 30050; Unsup length 14950\n",
      "\t\tResulting Sup length 40050; Unsup length 4950\n",
      "running top-K mode with K=10,000...\n",
      "for step 5 will add 4950 to supervised list\n",
      "\t\tStarting Sup length 40050; Unsup length 4950\n",
      "\t\tResulting Sup length 45000; Unsup length 0\n",
      "running top-K mode with K=10,000...\n",
      "\twent through 6 iterations before stopping\n",
      "final validation accuracy: 0.678\n",
      "FINAL TEST ACCURACY: 0.686\n",
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 500 and unsup size: 44500\n",
      "starting validation accuracy: 0.776\n",
      "running top-K mode with K=10,000...\n",
      "for step 1 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 500; Unsup length 44500\n",
      "\t\tResulting Sup length 10500; Unsup length 34500\n",
      "running top-K mode with K=10,000...\n",
      "for step 2 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 10500; Unsup length 34500\n",
      "\t\tResulting Sup length 20500; Unsup length 24500\n",
      "running top-K mode with K=10,000...\n",
      "for step 3 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 20500; Unsup length 24500\n",
      "\t\tResulting Sup length 30500; Unsup length 14500\n",
      "running top-K mode with K=10,000...\n",
      "for step 4 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 30500; Unsup length 14500\n",
      "\t\tResulting Sup length 40500; Unsup length 4500\n",
      "running top-K mode with K=10,000...\n",
      "for step 5 will add 4500 to supervised list\n",
      "\t\tStarting Sup length 40500; Unsup length 4500\n",
      "\t\tResulting Sup length 45000; Unsup length 0\n",
      "running top-K mode with K=10,000...\n",
      "\twent through 6 iterations before stopping\n",
      "final validation accuracy: 0.7116\n",
      "FINAL TEST ACCURACY: 0.7032\n",
      "first 10 indexes for labeled data are: [13943, 20707, 32369, 12727, 26056, 27326, 40446, 11116, 41270, 12688]\n",
      "sup data size: 5000 and unsup size: 40000\n",
      "starting validation accuracy: 0.826\n",
      "running top-K mode with K=10,000...\n",
      "for step 1 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 5000; Unsup length 40000\n",
      "\t\tResulting Sup length 15000; Unsup length 30000\n",
      "running top-K mode with K=10,000...\n",
      "for step 2 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 15000; Unsup length 30000\n",
      "\t\tResulting Sup length 25000; Unsup length 20000\n",
      "running top-K mode with K=10,000...\n",
      "for step 3 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 25000; Unsup length 20000\n",
      "\t\tResulting Sup length 35000; Unsup length 10000\n",
      "running top-K mode with K=10,000...\n",
      "for step 4 will add 10000 to supervised list\n",
      "\t\tStarting Sup length 35000; Unsup length 10000\n",
      "\t\tResulting Sup length 45000; Unsup length 0\n",
      "running top-K mode with K=10,000...\n",
      "\twent through 5 iterations before stopping\n",
      "final validation accuracy: 0.7312\n",
      "FINAL TEST ACCURACY: 0.7232\n"
     ]
    }
   ],
   "source": [
    "start_sizes = [50, 500, 5000]\n",
    "\n",
    "for s in start_sizes:\n",
    "    run_semi_supervised(k = 0.1, starting_size = s, mode = 'top-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
